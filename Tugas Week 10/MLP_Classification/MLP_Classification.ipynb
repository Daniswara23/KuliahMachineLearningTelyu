{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "e7mqV45-PYS5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bagian ini mengimpor pustaka-pustaka yang diperlukan:\n",
        "\n",
        "- torch dan torch.nn: Pustaka utama PyTorch untuk deep learning\n",
        "- pandas dan numpy: Untuk manipulasi data dan operasi numerik\n",
        "- Komponen sklearn: Untuk pra-pemrosesan data\n",
        "- Dataset dan DataLoader: Kelas PyTorch untuk penanganan data yang efisien"
      ],
      "metadata": {
        "id": "5AdelgwORZAL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom Dataset class for handling our data\n",
        "class BankDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.FloatTensor(X)\n",
        "        self.y = torch.LongTensor(y)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n"
      ],
      "metadata": {
        "id": "k3MKgO2kQV-E"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kelas ini mengubah data menjadi tensor PyTorch:\n",
        "\n",
        "- FloatTensor untuk fitur (X) karena jaringan saraf bekerja dengan angka desimal\n",
        "- LongTensor untuk label (y) karena klasifikasi menggunakan label kelas berupa bilangan bulat"
      ],
      "metadata": {
        "id": "9sunr4nyRbTJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP Model class with flexible architecture\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_size, hidden_layers, neurons_per_layer, activation_func):\n",
        "        super(MLP, self).__init__()\n",
        "\n",
        "        # Create layer list to hold all layers\n",
        "        layers = []\n",
        "\n",
        "        # Input layer to first hidden layer\n",
        "        layers.append(nn.Linear(input_size, neurons_per_layer))\n",
        "        layers.append(self._get_activation(activation_func))\n",
        "\n",
        "        # Additional hidden layers\n",
        "        for _ in range(hidden_layers - 1):\n",
        "            layers.append(nn.Linear(neurons_per_layer, neurons_per_layer))\n",
        "            layers.append(self._get_activation(activation_func))\n",
        "\n",
        "        # Output layer\n",
        "        layers.append(nn.Linear(neurons_per_layer, 2))  # Binary classification\n",
        "\n",
        "        # Combine all layers into sequential model\n",
        "        self.model = nn.Sequential(*layers)\n",
        "\n",
        "    def _get_activation(self, name):\n",
        "        activations = {\n",
        "            'linear': nn.Identity(),\n",
        "            'relu': nn.ReLU(),\n",
        "            'sigmoid': nn.Sigmoid(),\n",
        "            'tanh': nn.Tanh()\n",
        "        }\n",
        "        return activations.get(name.lower(), nn.ReLU())\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n"
      ],
      "metadata": {
        "id": "BbukoxW4QYsh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ini mendefinisikan kelas Multi-Layer Perceptron dengan parameter yang fleksibel:\n",
        "\n",
        "- input_size: Jumlah fitur input\n",
        "- hidden_layers: Jumlah layer tersembunyi (1, 2, atau 3 dalam eksperimen kita)\n",
        "- neurons_per_layer: Jumlah neuron di setiap layer tersembunyi\n",
        "- activation_func: Jenis fungsi aktivasi yang digunakan"
      ],
      "metadata": {
        "id": "dWD5x6aaRmxG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(data):\n",
        "    # Convert categorical variables to numerical\n",
        "    le = LabelEncoder()\n",
        "    categorical_columns = ['job', 'marital', 'education', 'default', 'housing',\n",
        "                         'loan', 'contact', 'month', 'poutcome', 'y']\n",
        "\n",
        "    for col in categorical_columns:\n",
        "        data[col] = le.fit_transform(data[col])\n",
        "\n",
        "    # Separate features and target\n",
        "    X = data.drop('y', axis=1).values\n",
        "    y = data['y'].values\n",
        "\n",
        "    # Scale features\n",
        "    scaler = StandardScaler()\n",
        "    X = scaler.fit_transform(X)\n",
        "\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "DIWymtuYQaoc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ini membangun arsitektur jaringan secara dinamis:\n",
        "\n",
        "- Layer pertama menghubungkan fitur input ke layer tersembunyi pertama\n",
        "- Setiap layer tersembunyi memiliki jumlah neuron yang sama\n",
        "- Fungsi aktivasi disisipkan di antara layer linear\n"
      ],
      "metadata": {
        "id": "o1XjeJc7RtrB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Calculate accuracy\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    return total_loss / len(train_loader), 100 * correct / total"
      ],
      "metadata": {
        "id": "7vmxOC0mQc8x"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loop pelatihan melaksanakan langkah-langkah penting:\n",
        "\n",
        "- Mengatur model ke mode pelatihan\n",
        "- Memproses batch data melalui jaringan\n",
        "- Menghitung loss dan memperbarui bobot melalui backpropagation\n",
        "- Melacak statistik akurasi dan loss\n",
        "- Pemanggilan model.train() penting karena mengaktifkan perhitungan gradien"
      ],
      "metadata": {
        "id": "PlgZvQ_2Rxo_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def evaluate_model(model, test_loader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    return total_loss / len(test_loader), 100 * correct / total"
      ],
      "metadata": {
        "id": "oZN0_3-YQfEu"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fungsi ini:\n",
        "\n",
        "- Mengatur model ke mode evaluasi\n",
        "- Menonaktifkan perhitungan gradien untuk efisiensi\n",
        "- Menghitung loss dan akurasi pada data uji\n",
        "- Menggunakan torch.no_grad() untuk menghemat memori saat inferensi"
      ],
      "metadata": {
        "id": "Y4VDWDd7R8pK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_experiment(config):\n",
        "    # Set device\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Load and preprocess data\n",
        "    data = pd.read_csv('/content/sample_data/bank-full.csv', sep=';')\n",
        "    X, y = preprocess_data(data)\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Create data loaders\n",
        "    train_dataset = BankDataset(X_train, y_train)\n",
        "    test_dataset = BankDataset(X_test, y_test)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=config['batch_size'])\n",
        "\n",
        "    # Initialize model\n",
        "    model = MLP(\n",
        "        input_size=X.shape[1],\n",
        "        hidden_layers=config['hidden_layers'],\n",
        "        neurons_per_layer=config['neurons'],\n",
        "        activation_func=config['activation']\n",
        "    ).to(device)\n",
        "\n",
        "    # Define loss function and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
        "\n",
        "    # Training loop\n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "    train_accuracies = []\n",
        "    test_accuracies = []\n",
        "\n",
        "    for epoch in range(config['epochs']):\n",
        "        train_loss, train_acc = train_model(model, train_loader, criterion, optimizer, device)\n",
        "        test_loss, test_acc = evaluate_model(model, test_loader, criterion, device)\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        test_losses.append(test_loss)\n",
        "        train_accuracies.append(train_acc)\n",
        "        test_accuracies.append(test_acc)\n",
        "\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            print(f'Epoch [{epoch+1}/{config[\"epochs\"]}], '\n",
        "                  f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, '\n",
        "                  f'Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%')\n",
        "\n",
        "    return {\n",
        "        'final_train_acc': train_accuracies[-1],\n",
        "        'final_test_acc': test_accuracies[-1],\n",
        "        'train_losses': train_losses,\n",
        "        'test_losses': test_losses,\n",
        "        'train_accuracies': train_accuracies,\n",
        "        'test_accuracies': test_accuracies\n",
        "    }"
      ],
      "metadata": {
        "id": "Icvw7THPQjfC"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ini mengatur seluruh proses pelatihan:\n",
        "\n",
        "- Memilih GPU secara otomatis jika tersedia\n",
        "- Membuat data loader dengan ukuran batch yang ditentukan\n",
        "- Menginisialisasi model dengan konfigurasi yang diberikan\n",
        "- Menjalankan loop pelatihan untuk jumlah epoch yang ditentukan\n",
        "- Mencatat dan mengembalikan metrik kinerja"
      ],
      "metadata": {
        "id": "AG35t_S-SCmg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment configurations\n",
        "hidden_layers = [1, 2, 3]\n",
        "neurons = [4, 8, 16, 32, 64]\n",
        "activations = ['linear', 'sigmoid', 'relu', 'tanh']\n",
        "epochs = [1, 10, 25, 50, 100, 250]\n",
        "learning_rates = [10, 1, 0.1, 0.01, 0.001, 0.0001]\n",
        "batch_sizes = [16, 32, 64, 128, 256, 512]\n",
        "\n",
        "# Store results\n",
        "results = []\n",
        "\n",
        "# Run base experiment\n",
        "base_config = {\n",
        "    'hidden_layers': 2,\n",
        "    'neurons': 32,\n",
        "    'activation': 'relu',\n",
        "    'epochs': 50,\n",
        "    'learning_rate': 0.001,\n",
        "    'batch_size': 64\n",
        "}\n",
        "\n",
        "print(\"Running base configuration...\")\n",
        "base_results = run_experiment(base_config)\n",
        "results.append({\n",
        "    'config': base_config,\n",
        "    'results': base_results\n",
        "})\n",
        "\n",
        "# Example of running experiments for different hidden layers\n",
        "print(\"\\nTesting different numbers of hidden layers...\")\n",
        "for n_layers in hidden_layers:\n",
        "    config = base_config.copy()\n",
        "    config['hidden_layers'] = n_layers\n",
        "    results.append({\n",
        "        'config': config,\n",
        "        'results': run_experiment(config)\n",
        "    })\n",
        "\n",
        "# Print summary of results\n",
        "print(\"\\nSummary of Results:\")\n",
        "for result in results:\n",
        "    config = result['config']\n",
        "    metrics = result['results']\n",
        "    print(f\"\\nConfiguration:\")\n",
        "    print(f\"Hidden Layers: {config['hidden_layers']}\")\n",
        "    print(f\"Neurons: {config['neurons']}\")\n",
        "    print(f\"Activation: {config['activation']}\")\n",
        "    print(f\"Epochs: {config['epochs']}\")\n",
        "    print(f\"Learning Rate: {config['learning_rate']}\")\n",
        "    print(f\"Batch Size: {config['batch_size']}\")\n",
        "    print(f\"Final Test Accuracy: {metrics['final_test_acc']:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaQvxwBYQn15",
        "outputId": "b3b8998f-75d6-4800-e616-98f014d3a333"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running base configuration...\n",
            "Epoch [10/50], Train Loss: 0.2213, Train Acc: 90.52%, Test Loss: 0.2353, Test Acc: 89.72%\n",
            "Epoch [20/50], Train Loss: 0.2128, Train Acc: 90.86%, Test Loss: 0.2318, Test Acc: 90.10%\n",
            "Epoch [30/50], Train Loss: 0.2086, Train Acc: 90.91%, Test Loss: 0.2294, Test Acc: 90.28%\n",
            "Epoch [40/50], Train Loss: 0.2037, Train Acc: 91.22%, Test Loss: 0.2333, Test Acc: 89.90%\n",
            "Epoch [50/50], Train Loss: 0.1996, Train Acc: 91.30%, Test Loss: 0.2316, Test Acc: 90.14%\n",
            "\n",
            "Testing different numbers of hidden layers...\n",
            "Epoch [10/50], Train Loss: 0.2276, Train Acc: 90.23%, Test Loss: 0.2387, Test Acc: 90.01%\n",
            "Epoch [20/50], Train Loss: 0.2223, Train Acc: 90.43%, Test Loss: 0.2365, Test Acc: 89.90%\n",
            "Epoch [30/50], Train Loss: 0.2195, Train Acc: 90.56%, Test Loss: 0.2355, Test Acc: 89.91%\n",
            "Epoch [40/50], Train Loss: 0.2181, Train Acc: 90.61%, Test Loss: 0.2348, Test Acc: 89.90%\n",
            "Epoch [50/50], Train Loss: 0.2170, Train Acc: 90.65%, Test Loss: 0.2360, Test Acc: 89.74%\n",
            "Epoch [10/50], Train Loss: 0.2221, Train Acc: 90.41%, Test Loss: 0.2382, Test Acc: 89.93%\n",
            "Epoch [20/50], Train Loss: 0.2134, Train Acc: 90.80%, Test Loss: 0.2354, Test Acc: 89.98%\n",
            "Epoch [30/50], Train Loss: 0.2083, Train Acc: 91.05%, Test Loss: 0.2332, Test Acc: 90.15%\n",
            "Epoch [40/50], Train Loss: 0.2038, Train Acc: 91.18%, Test Loss: 0.2350, Test Acc: 89.93%\n",
            "Epoch [50/50], Train Loss: 0.2007, Train Acc: 91.35%, Test Loss: 0.2364, Test Acc: 90.06%\n",
            "Epoch [10/50], Train Loss: 0.2177, Train Acc: 90.54%, Test Loss: 0.2363, Test Acc: 89.72%\n",
            "Epoch [20/50], Train Loss: 0.2075, Train Acc: 90.97%, Test Loss: 0.2360, Test Acc: 89.73%\n",
            "Epoch [30/50], Train Loss: 0.1997, Train Acc: 91.15%, Test Loss: 0.2335, Test Acc: 89.79%\n",
            "Epoch [40/50], Train Loss: 0.1933, Train Acc: 91.49%, Test Loss: 0.2374, Test Acc: 89.58%\n",
            "Epoch [50/50], Train Loss: 0.1886, Train Acc: 91.73%, Test Loss: 0.2420, Test Acc: 89.68%\n",
            "\n",
            "Summary of Results:\n",
            "\n",
            "Configuration:\n",
            "Hidden Layers: 2\n",
            "Neurons: 32\n",
            "Activation: relu\n",
            "Epochs: 50\n",
            "Learning Rate: 0.001\n",
            "Batch Size: 64\n",
            "Final Test Accuracy: 90.14%\n",
            "\n",
            "Configuration:\n",
            "Hidden Layers: 1\n",
            "Neurons: 32\n",
            "Activation: relu\n",
            "Epochs: 50\n",
            "Learning Rate: 0.001\n",
            "Batch Size: 64\n",
            "Final Test Accuracy: 89.74%\n",
            "\n",
            "Configuration:\n",
            "Hidden Layers: 2\n",
            "Neurons: 32\n",
            "Activation: relu\n",
            "Epochs: 50\n",
            "Learning Rate: 0.001\n",
            "Batch Size: 64\n",
            "Final Test Accuracy: 90.06%\n",
            "\n",
            "Configuration:\n",
            "Hidden Layers: 3\n",
            "Neurons: 32\n",
            "Activation: relu\n",
            "Epochs: 50\n",
            "Learning Rate: 0.001\n",
            "Batch Size: 64\n",
            "Final Test Accuracy: 89.68%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "segment ini mendefinisikan parameter eksperimen:\n",
        "\n",
        "- Hidden layers: Menguji dampak kedalaman jaringan\n",
        "- Neurons: Memeriksa efek lebar jaringan\n",
        "- Activations: Membandingkan fungsi non-linear berbeda\n",
        "- Learning rates: Rentang dari sangat besar (10) hingga sangat kecil (0.0001)\n",
        "- Batch sizes: Menguji ukuran batch pelatihan berbeda\n",
        "- Epochs: Memvariasikan durasi pelatihan\n",
        "\n",
        "Mendefinisikan konfigurasi dasar untuk perbandingan kemudiaMenyimpan hasil dalam format terstruktur yang Memungkinkan perbandingan sistematis arsitektur berbeda lalu Konfigurasi dasar menggunakan nilai-nilai yang umumnya efektif sebagai titik awal.\n"
      ],
      "metadata": {
        "id": "gyi9TemDUQ6T"
      }
    }
  ]
}